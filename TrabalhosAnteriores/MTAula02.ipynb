{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 02 - ExpressÃµes regulares e TokenizaÃ§Ã£o\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "\n",
      "teste\\n\n",
      "[' ', ' ', ' ', '      ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['preÃ§o', 'ovo']\n",
      "['11', '00', '28', '00']\n",
      "['R$11,00', 'R$28,00']\n",
      "['Os preÃ§os estÃ£o absurdos!!!      Bandeja de ovos subiu de R$', ',', ' para R$', ',', ' em uma semana']\n",
      "[' ', ' ', ' ', '      ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['O', 's', 'p', 'r', 'e', 'Ã§', 'o', 's', 'e', 's', 't', 'Ã£', 'o', 'a', 'b', 's', 'u', 'r', 'd', 'o', 's', 'B', 'a', 'n', 'd', 'e', 'j', 'a', 'd', 'e', 'o', 'v', 'o', 's', 's', 'u', 'b', 'i', 'u', 'd', 'e', 'R', '1', '1', '0', '0', 'p', 'a', 'r', 'a', 'R', '2', '8', '0', '0', 'e', 'm', 'u', 'm', 'a', 's', 'e', 'm', 'a', 'n', 'a']\n",
      "['O', 's', 'p', 'r', 'e', 'Ã§', 'o', 's', 'e', 's', 't', 'Ã£', 'o', 'a', 'b', 's', 'u', 'r', 'd', 'o', 's', '!', '!', '!', 'B', 'a', 'n', 'd', 'e', 'j', 'a', 'd', 'e', 'o', 'v', 'o', 's', 's', 'u', 'b', 'i', 'u', 'd', 'e', 'R', '$', '1', '1', ',', '0', '0', 'p', 'a', 'r', 'a', 'R', '$', '2', '8', ',', '0', '0', 'e', 'm', 'u', 'm', 'a', 's', 'e', 'm', 'a', 'n', 'a']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#colocar um \"r\" antes de uma string (qualquer que seja), indica ao Python para ignorar \n",
    "#todos os caracteres considerados pelo Python (nÃ£o pelo mÃ³dulo re). O \"r\" vem de \"raw\". Por exemplo: \n",
    "print(\"teste\\n\")\n",
    "print(r\"teste\\n\")\n",
    " \n",
    "my_string = \"Os preÃ§os estÃ£o absurdos!!!      Bandeja de ovos subiu de R$11,00 para R$28,00 em uma semana\"\n",
    "\n",
    "print(re.findall(r\"\\s+\", my_string))          # \\s - espacos\n",
    "print(re.findall(r\"[Pp]reÃ§o|ovo\", my_string)) # caracteres alternativos P ou p\n",
    "print(re.findall(r\"[0-9]+\", my_string))      # intervalo de caracteres\n",
    "print(re.findall(r\"[Rr]\\$[0-9]+,[0-9]+\", my_string)) # usar o \\ antes de caracteres especiais\n",
    "print(re.findall(r\"[^0-9]+\", my_string))             # todos os caracteres exceto qq sequencia dos digitos 0-9\n",
    "\n",
    "#d (Procurar qualquer dÃ­gito, ou seja [0-9]) \n",
    "#D (Procurar por qualquer nÃ£o dÃ­gito, ou seja [^0-9])\n",
    "#s (Procurar por qualquer espaÃ§o em branco, ou seja [ tnrfv] (whitespace, tabs, newlines, return carriages, etc.)) \n",
    "#S (Procurar por qualquer carÃ¡cter que nÃ£o seja um espaÃ§o em branco, ou seja, [^ tnrfv])\n",
    "#w (Procurar por qualquer carÃ¡cter alfanumÃ©rico, ou seja [a-zA-Z0-9_]). \n",
    "#W (Procurar por um carÃ¡cter que nÃ£o seja alfanumÃ©rico, ou seja, [^a-zA-Z0-9_]). \n",
    "\n",
    "print(re.findall(r\"\\s+\", my_string))         \n",
    "print(re.findall(r\"\\w\", my_string))\n",
    "print(re.findall(r\"\\S\", my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lol']\n",
      "[]\n",
      "['lol']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(\"^lol\") # ^ corresponde ao inicio da string\n",
    "print(re.findall(pattern, \"lolasdfasdf\"))\n",
    "print(re.findall(pattern, \"1234lolasdfasdf\")) # Isto nao vai funcionar porque o \"lol\" nao se encontra no inicio da string\n",
    "pattern = re.compile(\"lol$\") # $ corresponde ao fim da string\n",
    "print(re.findall(pattern, \"asdfasdflol\"))\n",
    "print(re.findall(pattern, \"asdfasdlolf\")) # Isto nao vai dar funcionar porque o \"lol\" nao se encontra no fim da string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aai!', 'Aaaaaaiiiii!', 'Aaaaiii!', 'Aaaiiiii!']\n",
      "['Aai!', 'Aaaaaaiiiii!', 'Aaaaiii!', 'Aaaiiiii!', 'Ai!', 'Aaaa!']\n",
      "['Aai!', 'Ai!']\n"
     ]
    }
   ],
   "source": [
    "#caracteres de repetiÃ§Ã£o +, *, e ?\n",
    "\n",
    "pattern = re.compile(\"Aa+i+!\") # + procura o caractere anterior por 1 ou mais vezes\n",
    "print(re.findall(pattern, \"Aai!, Aaaaaaiiiii!, Aaaaiii!, Aaaiiiii!, Ai!, Aaaa!\"))\n",
    "pattern = re.compile(\"Aa*i*!\") # * procura o caractere anterior por 0 ou mais vezes\n",
    "print(re.findall(pattern, \"Aai!, Aaaaaaiiiii!, Aaaaiii!, Aaaiiiii!, Ai!, Aaaa!\"))\n",
    "pattern = re.compile(\"Aa?i*!\") # ? procura o caractere anterior por 0 ou 1 vez\n",
    "print(re.findall(pattern, \"Aai!, Aaaaaaiiiii!, Aaaaiii!, Aaaiiiii!, Ai!, Aaaa!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------TEXTO--------\n",
      "\n",
      "@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\n",
      "\n",
      "\n",
      "--------TEXTO QUEBRADO POR ESPACOS--------\n",
      "\n",
      "['@USER', '@USER', 'Go', 'home', 'youâ€™re', 'drunk!!!', '@USER', '#MAGA', '#Trump2020', 'ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š', 'URL']\n",
      "\n",
      "\n",
      "--------TEXTO QUEBRADO POR SIMBOLOS DE PONTUACAO--------\n",
      "\n",
      "['@USER @USER Go home youâ€™re drunk', ' @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL']\n",
      "\n",
      "\n",
      "--------TEXTO QUEBRADO POR MENCOES--------\n",
      "\n",
      "['@USER', '@USER', '@USER']\n",
      "['', ' ', ' Go home youâ€™re drunk!!! ', ' #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#my_string = \"Let's write RegEx!!!  Won't that be fun?  I sure think so.  Can you find 44 sentences?  Or perhaps, all 19 words?\"\n",
    "my_string = \"@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\"\n",
    "\n",
    "print(\"--------TEXTO--------\\n\")\n",
    "print(my_string)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--------TEXTO QUEBRADO POR ESPACOS--------\\n\")\n",
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, my_string))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--------TEXTO QUEBRADO POR SIMBOLOS DE PONTUACAO--------\\n\")\n",
    "# Split my_string on sentence endings and print the result\n",
    "pontuacao = r\"[.?:!]+\"\n",
    "print(re.split(pontuacao, my_string))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--------TEXTO QUEBRADO POR MENCOES--------\\n\")\n",
    "# Find all mencoes com @ in my_string and print the result\n",
    "mencoes = r\"@\\w+\"\n",
    "print(re.findall(mencoes, my_string))\n",
    "print(re.split(mencoes, my_string))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "------- SENTENCAS -------\n",
      "['@USER @USER Go home youâ€™re drunk!!!', '@USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL']\n",
      " \n",
      "------- TOKENS DA 1a. SENTENCA -------\n",
      "['@', 'USER', '@', 'USER', 'Go', 'home', 'you', 'â€™', 're', 'drunk', '!', '!', '!']\n",
      " \n",
      "------- TOKENS DO TEXTO -------\n",
      "{'Go', 'â€™', 'USER', 'home', 'you', 'Trump2020', '@', 're', '!', 'MAGA', 'URL', 'drunk', '#', 'ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Avell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texto1 = \"@USER Canada doesnâ€™t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\"\n",
    "texto = \"@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\"\n",
    "\n",
    "# Import necessary modules\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(texto)\n",
    "print(' ')\n",
    "print('------- SENTENCAS -------')\n",
    "print(sentences)\n",
    "\n",
    "# Use word_tokenize to tokenize the sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[0])\n",
    "print(' ')\n",
    "print('------- TOKENS DA 1a. SENTENCA -------')\n",
    "print(tokenized_sent)\n",
    "\n",
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(texto))\n",
    "\n",
    "# Print the unique tokens result\n",
    "print(' ')\n",
    "print('------- TOKENS DO TEXTO -------')\n",
    "print(unique_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
